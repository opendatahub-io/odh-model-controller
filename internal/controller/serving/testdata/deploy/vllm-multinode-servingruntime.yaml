apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: vllm-multinode-runtime
  namespace: default
spec:
  annotations:
    prometheus.io/path: /metrics
    prometheus.io/port: "8080"
  containers:
  - args:
    - "ray start --head --disable-usage-stats --include-dashboard false \n# wait for
      other node to join\nuntil [[ $(ray status --address ${RAY_ADDRESS} | grep -c
      node_) -eq ${PIPELINE_PARALLEL_SIZE} ]]; do\n  echo \"Waiting...\"\n  sleep
      1\ndone\nray status --address ${RAY_ADDRESS}\n\nexport SERVED_MODEL_NAME=${MODEL_NAME}\nexport
      MODEL_NAME=${MODEL_DIR} \n\nexec python3 -m vllm.entrypoints.openai.api_server
      --port=8080 --distributed-executor-backend ray --model=${MODEL_NAME} --served-model-name=${SERVED_MODEL_NAME}
      --tensor-parallel-size=${TENSOR_PARALLEL_SIZE} --pipeline-parallel-size=${PIPELINE_PARALLEL_SIZE}
      --disable_custom_all_reduce\n"
    command:
    - bash
    - -c
    env:
    - name: RAY_USE_TLS
      value: "1"
    - name: RAY_TLS_SERVER_CERT
      value: /etc/ray/tls/tls.pem
    - name: RAY_TLS_SERVER_KEY
      value: /etc/ray/tls/tls.pem
    - name: RAY_TLS_CA_CERT
      value: /etc/ray/tls/ca.crt
    - name: RAY_PORT
      value: "6379"
    - name: RAY_ADDRESS
      value: 127.0.0.1:6379
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: VLLM_NO_USAGE_STATS
      value: "1"
    - name: HOME
      value: /tmp
    - name: HF_HOME
      value: /tmp/hf_home
    image: quay.io/opendatahub/vllm:fast
    livenessProbe:
      exec:
        command:
        - bash
        - -c
        - |
          # Check if the registered ray nodes count is the same as PIPELINE_PARALLEL_SIZE
          gpu_status=$(ray status --address ${RAY_ADDRESS} | grep GPU)
          if [[ -z ${gpu_status} ]]; then
            echo "Unhealthy - GPU does not exist"
            exit 1
          fi

          used_gpu=$(echo "${gpu_status}" | awk '{print $1}' | cut -d'/' -f1)
          reserved_gpu=$(echo "${gpu_status}" | awk '{print $1}' | cut -d'/' -f2)

          # Determine health status based on GPU usage
          if [[ "${used_gpu}" != "${reserved_gpu}" ]]; then
            echo "Unhealthy - Used: ${used_gpu}, Reserved: ${reserved_gpu}"
            exit 1
          fi
      failureThreshold: 2
      periodSeconds: 5
      successThreshold: 1
      timeoutSeconds: 15
    name: kserve-container
    ports:
    - containerPort: 8080
      name: http
      protocol: TCP
    readinessProbe:
      exec:
        command:
        - bash
        - -c
        - "# Check if the registered nodes count matches PIPELINE_PARALLEL_SIZE\nregistered_node_count=$(ray
          status --address ${RAY_ADDRESS} | grep -c node_)\nif [[ ${registered_node_count}
          -ne \"${PIPELINE_PARALLEL_SIZE}\" ]]; then\n  echo \"Unhealthy - Registered
          nodes count (${registered_node_count}) does not match PIPELINE_PARALLEL_SIZE
          (${PIPELINE_PARALLEL_SIZE}).\"\n  exit 1\nfi\n\n# Check if the registered
          ray nodes count is the same as PIPELINE_PARALLEL_SIZE\ngpu_status=$(ray
          status --address ${RAY_ADDRESS} | grep GPU)\nif [[ -z ${gpu_status} ]];
          then\n  echo \"Unhealthy - GPU does not exist\"\n  exit 1\nfi\n\nused_gpu=$(echo
          \"${gpu_status}\" | awk '{print $1}' | cut -d'/' -f1)\nreserved_gpu=$(echo
          \"${gpu_status}\" | awk '{print $1}' | cut -d'/' -f2)\n\n# Determine health
          status based on GPU usage\nif [[ \"${used_gpu}\" != \"${reserved_gpu}\"
          ]]; then\n  echo \"Unhealthy - Used: ${used_gpu}, Reserved: ${reserved_gpu}\"\n
          \ exit 1\nfi\n\n# Check model health \nhealth_check=$(curl -o /dev/null
          -s -w \"%{http_code}\\n\" http://localhost:8080/health)\nif [[ ${health_check}
          != 200 ]]; then\n  echo \"Unhealthy - vLLM Runtime Health Check failed.\"
          \n  exit 1\nfi\n"
      failureThreshold: 2
      periodSeconds: 5
      successThreshold: 1
      timeoutSeconds: 15
    resources:
      limits:
        cpu: "16"
        memory: 48Gi
      requests:
        cpu: "8"
        memory: 24Gi
    startupProbe:
      exec:
        command:
        - bash
        - -c
        - "# This need when head node have issues and restarted.\n# It will wait for
          new worker node.                     \nregistered_node_count=$(ray status
          --address ${RAY_ADDRESS} | grep -c node_)\nif [[ ${registered_node_count}
          -ne \"${PIPELINE_PARALLEL_SIZE}\" ]]; then\n  echo \"Unhealthy - Registered
          nodes count (${registered_node_count}) does not match PIPELINE_PARALLEL_SIZE
          (${PIPELINE_PARALLEL_SIZE}).\"\n  exit 1\nfi\n\n# Double check to make sure
          Model is ready to serve.\nfor i in 1 2; do                    \n  # Check
          model health\n  health_check=$(curl -o /dev/null -s -w \"%{http_code}\\n\"
          http://localhost:8080/health)\n  if [[ ${health_check} != 200 ]]; then\n
          \   echo \"Unhealthy - vLLM Runtime Health Check failed.\" \n    exit 1\n
          \ fi\ndone\n"
      failureThreshold: 40
      initialDelaySeconds: 20
      periodSeconds: 30
      successThreshold: 1
      timeoutSeconds: 30
    volumeMounts:
    - mountPath: /dev/shm
      name: shm
    - mountPath: /etc/ray/tls
      name: ray-tls
  multiModel: false
  supportedModelFormats:
  - autoSelect: true
    name: vLLM
    priority: 2
  volumes:
  - emptyDir:
      medium: Memory
      sizeLimit: 12Gi
    name: shm
  - emptyDir: {}
    name: ray-tls
  workerSpec:
    containers:
    - args:
      - "SECONDS=0\n\nwhile true; do              \n  if (( SECONDS <= 240 )); then\n
        \   if ray health-check --address \"${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:6379\"
        > /dev/null 2>&1; then\n      echo \"Global Control Service(GCS) is ready.\"\n
        \     break\n    fi\n    echo \"$SECONDS seconds elapsed: Waiting for Global
        Control Service(GCS) to be ready.\"\n  else\n    if ray health-check --address
        \"${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:6379\"; then\n      echo
        \"Global Control Service(GCS) is ready. Any error messages above can be safely
        ignored.\"\n      break\n    fi\n    echo \"$SECONDS seconds elapsed: Still
        waiting for Global Control Service(GCS) to be ready.\"\n    echo \"For troubleshooting,
        refer to the FAQ at https://docs.ray.io/en/master/cluster/kubernetes/troubleshooting/troubleshooting.html#kuberay-troubleshootin-guides\"\n
        \ fi\n\n  sleep 5\ndone\n\nexport RAY_HEAD_ADDRESS=\"${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:6379\"\necho
        \"Attempting to connect to Ray cluster at $RAY_HEAD_ADDRESS ...\"\nray start
        --address=\"${RAY_HEAD_ADDRESS}\" --block\n"
      command:
      - bash
      - -c
      env:
      - name: RAY_USE_TLS
        value: "1"
      - name: RAY_TLS_SERVER_CERT
        value: /etc/ray/tls/tls.pem
      - name: RAY_TLS_SERVER_KEY
        value: /etc/ray/tls/tls.pem
      - name: RAY_TLS_CA_CERT
        value: /etc/ray/tls/ca.crt
      - name: POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: POD_IP
        valueFrom:
          fieldRef:
            fieldPath: status.podIP
      image: quay.io/opendatahub/vllm:fast
      livenessProbe:
        exec:
          command:
          - bash
          - -c
          - |
            # Check if the registered nodes count matches PIPELINE_PARALLEL_SIZE
            registered_node_count=$(ray status --address ${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:6379 | grep -c node_)
            if [[ ${registered_node_count} -ne "${PIPELINE_PARALLEL_SIZE}" ]]; then
              echo "Unhealthy - Registered nodes count (${registered_node_count}) does not match PIPELINE_PARALLEL_SIZE (${PIPELINE_PARALLEL_SIZE})."
              exit 1
            fi
        failureThreshold: 2
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 15
      name: worker-container
      resources:
        limits:
          cpu: "16"
          memory: 48Gi
        requests:
          cpu: "8"
          memory: 24Gi
      startupProbe:
        exec:
          command:
          - /bin/sh
          - -c
          - "registered_node_count=$(ray status --address ${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:6379
            | grep -c node_)\nif [[ ${registered_node_count} -ne \"${PIPELINE_PARALLEL_SIZE}\"
            ]]; then\n  echo \"Unhealthy - Registered nodes count (${registered_node_count})
            does not match PIPELINE_PARALLEL_SIZE (${PIPELINE_PARALLEL_SIZE}).\"\n
            \ exit 1\nfi  \n\n# Double check to make sure Model is ready to serve.\nfor
            i in 1 2; do\n  # Check model health\n  model_health_check=$(curl -s ${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:8080/v1/models|grep
            -o ${ISVC_NAME})\n  if [[ ${model_health_check} != \"${ISVC_NAME}\" ]];
            then\n    echo \"Unhealthy - vLLM Runtime Health Check failed.\"\n    exit
            1\n  fi                     \n  sleep 10\ndone\n"
        failureThreshold: 40
        initialDelaySeconds: 20
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 30
      volumeMounts:
      - mountPath: /dev/shm
        name: shm
      - mountPath: /etc/ray/tls
        name: ray-tls
    pipelineParallelSize: 2
    tensorParallelSize: 1
    volumes:
    - emptyDir:
        medium: Memory
        sizeLimit: 12Gi
      name: shm
    - emptyDir: {}
      name: ray-tls
